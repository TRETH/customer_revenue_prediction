{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "from operator import itemgetter\n",
    "import pprint\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train data\n",
    "train_data = pd.read_csv('data/train_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain first overview on columns and data types\n",
    "train_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set column witdh to maximum in order to view full string object\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "#Display values in first row in \"train\" pandas dataframe\n",
    "display(train_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test data\n",
    "test_data = pd.read_csv('data/test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain first overview on columns and data types\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to convert JSON Objects to pandas columns. This function is borrowed from the following kernel:\n",
    "#https://www.kaggle.com/dimitreoliveira/lgbm-google-store-revenue-prediction\n",
    "\n",
    "def load_df(file_name = 'train_v2.csv', nrows = None):\n",
    "    USE_COLUMNS = [\n",
    "        'channelGrouping', 'date', 'device', 'fullVisitorId', 'geoNetwork',\n",
    "        'socialEngagementType', 'totals', 'trafficSource', 'visitId',\n",
    "        'visitNumber', 'visitStartTime', 'customDimensions']\n",
    "\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    df = pd.read_csv('data/{}'.format(file_name),\n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, nrows=nrows, usecols=USE_COLUMNS)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "        \n",
    "    # Normalize customDimensions\n",
    "    df['customDimensions']=df['customDimensions'].apply(literal_eval)\n",
    "    df['customDimensions']=df['customDimensions'].str[0]\n",
    "    df['customDimensions']=df['customDimensions'].apply(lambda x: {'index':np.NaN,'value':np.NaN} if pd.isnull(x) else x)\n",
    "\n",
    "    column_as_df = json_normalize(df['customDimensions'])\n",
    "    column_as_df.columns = [f\"customDimensions.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "    df = df.drop('customDimensions', axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert train and test data set\n",
    "train = load_df('train_v2.csv')\n",
    "test = load_df('test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display converted train data set\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first rows with values for converted train data set\n",
    "train.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first rows with values for converted test data set\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show difference in columns between train and test data set\n",
    "train.columns.difference(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical data for missing values to np.nan, in order to facilitate further ML processing\n",
    "train=train.replace(['(not set)','not available in demo dataset','(not provided)','unknown.unknown','(none)'], np.nan)\n",
    "test=test.replace(['(not set)','not available in demo dataset','(not provided)','unknown.unknown','(none)'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count unique values per train feature and display values for value count == 1\n",
    "col_uni_val_train={}\n",
    "for i in train.columns:\n",
    "    col_uni_val_train[i] = len(train[i].unique())\n",
    "    if len(train[i].unique()) == 7252:\n",
    "        pprint.pprint('Feature: {0} has the following values: {1}'.format(i,train[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count unique values per test feature and display values for value count == 1\n",
    "col_uni_val_test={}\n",
    "for i in test.columns:\n",
    "    col_uni_val_test[i] = len(test[i].unique())\n",
    "    if len(test[i].unique()) == 1:\n",
    "        pprint.pprint('Feature: {0} has the following values: {1}'.format(i,test[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort unique value count for train data set\n",
    "sorted_col_uni_val_train = sorted(col_uni_val_train.items(), key=lambda kv: kv[1], reverse=True)\n",
    "pprint.pprint(sorted_col_uni_val_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort unique value count for test data set\n",
    "sorted_col_uni_val_test = sorted(col_uni_val_test.items(), key=lambda kv: kv[1], reverse=True)\n",
    "pprint.pprint(sorted_col_uni_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select those columns to the drop in train and test data set, that only contain one unique value\n",
    "cols_to_drop_train = [col for col in train.columns if ((train[col].nunique(dropna=False) == 1))]\n",
    "cols_to_drop_test = [col for col in test.columns if ((test[col].nunique(dropna=False) == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep unique values for the following column, as they are not of type np.nan\n",
    "for col in ['totals.visits']:\n",
    "    cols_to_drop_train.remove(col)\n",
    "    cols_to_drop_test.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute missing rates for each column in training data set based on null values\n",
    "d = []\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum() > 0:\n",
    "        rate = train[col].isnull().sum() * 100 / train.shape[0]\n",
    "        d.append((col, rate))\n",
    "\n",
    "#Display missing rates in descending order        \n",
    "missing_rate = pd.DataFrame(d, columns=('feature', 'rate'))\n",
    "pprint.pprint(missing_rate.sort_values('rate', ascending=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot graph to visualize missing rates in descending order\n",
    "f, ax = plt.subplots(figsize=(6, 15))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x='rate', y='feature', data=missing_rate.sort_values('rate', ascending=False),palette=\"rocket\")\n",
    "ax.set(xlabel='percentage missing rate per feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert string type in test and training data set to float type for further ML processing\n",
    "for col in ['totals.hits', 'totals.pageviews', 'totals.transactionRevenue','totals.newVisits','totals.visits',\\\n",
    "           'visitNumber', 'totals.timeOnSite']:\n",
    "    train[col] = train[col].astype(float)\n",
    "    test[col] = test[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert string type to date type for further ML processing\n",
    "train['date'] = pd.to_datetime(train['date'], format='%Y%m%d', errors='coerce')\n",
    "test['date'] = pd.to_datetime(test['date'], format='%Y%m%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by transaction revenue for each user where there is revenue\n",
    "grouped = train.groupby('fullVisitorId')['totals.transactionRevenue'].sum().reset_index()\n",
    "grouped = grouped.loc[grouped['totals.transactionRevenue'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[grouped['totals.transactionRevenue'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of paid transaction\n",
    "counts_train = train.loc[train['totals.transactionRevenue'] > 0, 'fullVisitorId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the number of paid transactions\n",
    "print('There are {0} paying users ({1} total) in train data.'.format(len(counts_train), train['fullVisitorId'].nunique()))\n",
    "for count in range(1,34):\n",
    "    pprint.pprint('{0} users ({1:.4f}% of paying) have {2} paid transaction.'.format(np.sum(counts_train == count), 100 * np.sum(counts_train == count) / len(counts_train),count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trv = train.groupby('fullVisitorId')['totals.transactionRevenue'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(trv.shape[0]), np.sort(np.log1p(trv[\"totals.transactionRevenue\"].values)))\n",
    "plt.xlabel('Customers', fontsize=12)\n",
    "plt.ylabel('TransactionRevenue', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot and compare the distribution of revenue between all transactions and all transactions per user\n",
    "x1 = train.groupby('fullVisitorId')['totals.transactionRevenue'].sum().reset_index()\n",
    "#x1 = grouped.loc[grouped['totals.transactionRevenue'].isna() == False]\n",
    "x1 = np.log1p(grouped.loc[grouped['totals.transactionRevenue'] > 0, 'totals.transactionRevenue'])\n",
    "x2 = np.log1p(train.loc[train['totals.transactionRevenue'].isna() == False, 'totals.transactionRevenue'])\n",
    "fig=plt.figure(figsize=(10,8))\n",
    "sns.distplot(x1)\n",
    "sns.distplot(x2)\n",
    "fig.legend(labels=['Revenue per user','Revenue'])\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_charts(y1, x1, y2, x2, data):\n",
    "    f, axes = plt.subplots(1,2,figsize=(18, 7))\n",
    "    \n",
    "    sns.set(style=\"darkgrid\")\n",
    "    sns.barplot(y=y1, x=x1, data=data,\n",
    "            label=\"Total\", ax=axes[0],palette=\"BuGn_r\")\n",
    "    \n",
    "    sns.set(style=\"darkgrid\")\n",
    "    sns.barplot(y=y2, x=x2, data=data,\n",
    "            label=\"Total\", ax=axes[1], palette=\"BuGn_r\")\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(data):\n",
    "    for feature in data:\n",
    "        data_bar_plot = train.groupby(feature)['totals.transactionRevenue'].agg(['size', 'count'])\n",
    "        data_bar_plot.columns = ['count', 'countOfTransactions']\n",
    "        data_bar_plot.reset_index(inplace=True)\n",
    "        data_bar_plot = data_bar_plot.sort_values(by=\"count\", ascending=False)\n",
    "        data_bar_plot = data_bar_plot[data_bar_plot.countOfTransactions > 0]\n",
    "        draw_charts(feature,'count',feature,'countOfTransactions', data_bar_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['geoNetwork.continent', 'geoNetwork.subContinent', 'device.browser', 'device.operatingSystem', \\\n",
    "            'trafficSource.source']\n",
    "plot_stats(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop additional features that are (a) not considered relevant due to EDA, (b) missing in the\n",
    "# test data set i.e. trafficSource.campaignCode, (c) that only have np.nan as value -> stored in cols_to_drop\n",
    "cols_to_drop_additional = [\"trafficSource.adContent\", \"trafficSource.adwordsClickInfo.adNetworkType\",\\\n",
    "                          \"trafficSource.adwordsClickInfo.gclId\", \"trafficSource.adwordsClickInfo.isVideoAd\", \\\n",
    "                          \"trafficSource.adwordsClickInfo.page\", \"trafficSource.adwordsClickInfo.slot\", \"visitId\",\\\n",
    "                          \"visitStartTime\", \"totals.bounces\", \"trafficSource.isTrueDirect\", \"trafficSource.medium\",\\\n",
    "                           \"trafficSource.campaignCode\", \"trafficSource.isTrueDirect\", \"customDimensions.index\",\\\n",
    "                          \"socialEngagementType\", \"geoNetwork.networkDomain\", \"customDimensions.value\",\\\n",
    "                          \"totals.totalTransactionRevenue\", \"totals.transactions\", \"geoNetwork.city\", \\\n",
    "                           \"fullVisitorId\",\"geoNetwork.metro\",\"totals.sessionQualityDim\", \"trafficSource.campaign\",\\\n",
    "                          \"trafficSource.keyword\",\"trafficSource.referralPath\",\"trafficSource.source\",\"geoNetwork.region\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lists for features that will be dropped and show number if dropped features\n",
    "cols_to_drop = cols_to_drop_train + cols_to_drop_additional\n",
    "sorted(cols_to_drop)\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in train and test data set\n",
    "train.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test.drop([col for col in cols_to_drop if col in test.columns], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assure that train and test data set have the same features/columns\n",
    "train.columns.difference(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of categorical features\n",
    "cat_features = ['channelGrouping','device.browser','device.deviceCategory','device.operatingSystem',\\\n",
    "               'geoNetwork.continent','geoNetwork.country','geoNetwork.subContinent','device.isMobile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare values in feature device.browser for one hot encoding, by removing invalid browser data\n",
    "relevent_browsers = ['Chrome', 'Internet Explorer', 'Safari (in-app)', 'Edge', 'Safari', 'Firefox', 'YaBrowser'\\\n",
    "                     'Opera', 'Android Webview', 'Opera Mini', 'UC Browser', 'Samsung Internet',\\\n",
    "                     'Amazon Silk', 'Mozilla Compatible Agent', 'Coc Coc','Maxthon', 'Android Browser', 'Puffin',\\\n",
    "                     'Playstation Vita Browser', 'Nokia Browser', 'Mozilla', '+Simple Browser','BlackBerry', 'BrowserNG',\\\n",
    "                     'SeaMonkey', 'Nintendo Browser', 'Iron', 'GemiusSDK']\n",
    "\n",
    "train.loc[~train['device.browser'].isin(relevent_browsers), 'device.browser'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup feature device.browser with relevant browser information from above\n",
    "test.loc[~test['device.browser'].isin(relevent_browsers), 'device.browser'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of categorical features in train data set\n",
    "train = pd.get_dummies(train, prefix_sep=\"__\",columns=cat_features,dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store newly created columns in variable for later use with the test set\n",
    "train_new_cat_columns = [col for col in train if \"__\" in col and col.split(\"__\")[0] in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of categorical features in test data set\n",
    "test = pd.get_dummies(test, prefix_sep=\"__\",columns=cat_features,dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show difference in columns between train and test data set\n",
    "train.columns.difference(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove addtional columns in test data set that are not in the train test data set\n",
    "for col in test.columns:\n",
    "    if (\"__\" in col) and (col.split(\"__\")[0] in cat_features) and col not in train_new_cat_columns:\n",
    "        print(\"Removing additional feature {}\".format(col))\n",
    "        test.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to test data set that are present in the train data set and not in the test data set\n",
    "for col in train:\n",
    "    if col not in test.columns:\n",
    "        print(\"Adding missing feature {}\".format(col))\n",
    "        test[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show difference in columns between train and test data set\n",
    "train.columns.difference(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort train and test data set by date for coming further train-validation-test processing\n",
    "train.sort_values(by=[\"date\"], inplace=True)\n",
    "test.sort_values(by=[\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with 0 in train and test data set\n",
    "train.replace(to_replace=np.nan, value=0, inplace=True)\n",
    "test.replace(to_replace=np.nan, value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and log transform target variable from train dataset\n",
    "target = np.log1p(pd.DataFrame(train['totals.transactionRevenue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sorted dates\n",
    "dates = pd.DataFrame(train[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['visitNumber', 'totals.timeOnSite']:\n",
    "    train[col] = train[col].astype(float)\n",
    "    test[col] = test[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data in training data set\n",
    "normalized_features = [\"visitNumber\", \"totals.hits\", \"totals.newVisits\", \"totals.pageviews\",\\\n",
    "                      \"totals.timeOnSite\", \"totals.visits\"]\n",
    "train[normalized_features] = np.log1p(train[normalized_features])\n",
    "test[normalized_features] = np.log1p(test[normalized_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target column from training data set\n",
    "train = train.drop(['totals.transactionRevenue'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"date\",axis=1, inplace=True)\n",
    "test.drop(\"date\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(X, y, dates, num_folds):\n",
    "    \n",
    "    k = int(np.floor(float(X.shape[0]) / num_folds))\n",
    "    \n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_val_list = []\n",
    "    y_val_list = []\n",
    "    dates_list = []\n",
    "        \n",
    "    for i in range(2, num_folds + 1):\n",
    "        \n",
    "        # percentage split\n",
    "        split = float(i-1)/i\n",
    "        \n",
    "        x_temp = X[:k*i]\n",
    "        y_temp = y[:k*i]\n",
    "        dates_list.append((dates.iloc[k*i]).values)\n",
    "        \n",
    "        # index to split current fold into train and test\n",
    "        index = int(np.floor(x_temp.shape[0] * split))\n",
    "        \n",
    "        X_train = x_temp[:index]\n",
    "        y_train = y_temp[:index]\n",
    "        \n",
    "        X_val = x_temp[index:]\n",
    "        y_val = y_temp[index:]\n",
    "        \n",
    "        X_train_list.append(X_train)\n",
    "        y_train_list.append(y_train)\n",
    "        X_val_list.append(X_val)\n",
    "        y_val_list.append(y_val)\n",
    "        \n",
    "    return X_train_list, y_train_list, X_val_list, y_val_list, dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, y_train_list, X_val_list, y_val_list, dates_list = k_fold_split(train, target, dates, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [X_train_list, y_train_list, X_val_list, y_val_list, dates_list]\n",
    "\n",
    "for i in sets:\n",
    "    for x in i:\n",
    "        print (x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metric(predict, true):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "\n",
    "    mse = mean_squared_error(predict, true)\n",
    "    rmse = np.sqrt(mean_squared_error(predict, true))\n",
    "    return mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    model = model.fit(X_train, y_train)\n",
    "\n",
    "    val_predictions = model.predict(X_val)\n",
    "    \n",
    "    mse, rmse = performance_metric(val_predictions, y_val)\n",
    "    \n",
    "    return mse, rmse\n",
    "\n",
    "    print('Validation MSE: %.2f' % mse)\n",
    "    print('Validation RMSE: %.2f' % rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()\n",
    "\n",
    "MSE = []\n",
    "RMSE = []\n",
    "\n",
    "for i in range(len(X_train_list)):\n",
    "    X_train = X_train_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    X_val = X_val_list[i]\n",
    "    y_val = y_val_list[i]\n",
    "    \n",
    "    mse, rmse = train_predict(model, X_train, y_train, X_val, y_val)\n",
    "    MSE.append(mse)\n",
    "    RMSE.append(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostRegressor MSE: [4.84129282810992, 5.187600044999533, 4.212516139896318, 4.657948530435676]\n",
    "XGBRegressor MSE: [2.8992694561282972, 3.1032612568445326, 1.6919413742623766, 2.0183806995223414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dates = pd.DataFrame(dates_list)\n",
    "new_dates['dates'] = new_dates[0].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))\n",
    "print (new_dates)\n",
    "\n",
    "dates_long = pd.DataFrame(dates)\n",
    "dates_long['date'] = dates_long['date'].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))\n",
    "dates_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_dates['dates'], MSE, 'go--', linewidth=2, markersize=2)\n",
    "plt.plot(new_dates['dates'], RMSE, 'bo-', linewidth=2, markersize=2)\n",
    "plt.legend(('MSE', 'RMSE'),\n",
    "        loc=(1, 1), handlelength=1.5, fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
